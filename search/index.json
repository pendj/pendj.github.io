[{"content":"开场白 您好,我叫XX.统招本科毕业于XX,有6年开发经验,2年管理经验,从0到1构建多个项目,可带3-5人小团队.具有独立完成复杂工作,指导初中级开发的能力.同时熟悉系统设计、性能优化、敏捷开发. 在上⼀个公司我参与了中国山东网项目开发,主要职责是对开源框架进行微服务改造,核心业务模块拆分以及负责开发一些与平台运营相关的系统.\n集合 List | ArrayList | LinkedList | CopyOnWriteArrayList Set | HashSet | LinkedHashSet | TreeSet Queue | PriorityQueue | BlockingQueue | DelayQueue Map | HashMap | LinkedHashMap | ConcurrentHashMap 多线程 线程的生命周期和状态 死锁 | 避免死锁 Java 内存模型 volatile 乐观锁与悲观锁 synchronized ReentrantLock | Condition ReentrantReadWriteLock | StampedLock ThreadLocal 线程池 | ThreadPoolExcutor | 参数 常见并发容器 AQS | 常见同步工具类 Semaphore (permits accquire(permits\u0026ndash;) release(permits++) ) 使用场景：控制并发访问量和单机限流 CountDownLatch (count countdown(count\u0026ndash;) await(count==0)) 使用场景：并行任务和同步操作 CyclicBarrier (parties await) 使用场景：主要应用场景和 CountDownLatch 类似 Atomic | CAS算法 Unsafe.compareAndSwap native CompletableFuture JVM 内存区域\n堆 + 字符串常量池 (对象实例 + 字符串) 程序计数器 (1. 字节码解释器改变程序计数器来依次读取指令,实现流程控制 2. 记录线程执行的位置) 栈 (栈帧\u0026ndash;\u0026gt; 局部变量表 + 操作数栈(中间计算结果) + 动态链接(调用其他方法时,将符号引用转化为直接引用) + 方法返回地址) 本地方法栈 (native方法 同栈帧) 方法区(元空间(类信息 + 字段信息 + 方法信息 + 静态变量 + 常量 + JIT编译后的代码缓存) + 运行时常量池(类符号引用 + 字段符号引用 + 方法符号引用 + 接口方法符号)) 本地内存 类创建过程\n加载(类加载器加载)\n连接\n验证(验证 class文件格式检查 字节码语义检查 程序语义检查 类正确性检查)\n准备(分配内存 初始化零值 设置对象头(类的元数据 哈希码 GC分代年龄 是否启用偏向锁))\n解析(将运行时常量池符号引用替换为直接引用,得到类、字段、方法在内存中的指针或偏移量)\n初始化(clinit() 调用构造方法)\n卸载(类的class对象被GC)\n实例对象被GC 没有被引用 类加载器被GC (BootstrapClassLoader,ExtClassLoader,AppClassLoader 不会被GC) 死亡对象判断算法 (引用计数 + 可达性分析)\nGC ROOTS对象：\n成员对象 静态对象 常量对象 实例对象 同步锁持有对象 native对象 引用类型\n强引用 不会被GC\n弱应用 被发现就会被GC\n软引用 内存不足,就会被GC\n虚引用 随时会被GC\n垃圾收集算法\n标记 - 清除 (先标记存活对象,标记完成后后清除剩余对象) 复制 (腾出一半空间,将可用对象复制到这片空间,然后清除另一半的空间) 标记 - 整理 (标记存活对象,然后向一端移动,清理端边界以外的对象) 垃圾收集器 (Serial + Serial Old | Paraller New (Paraller Scavenge + Paraller Old) | CMS (初始标记 -\u0026gt; 并发标记 - \u0026gt; 重新标记 -\u0026gt; 并发清除)| G1 | ZGC)\n类加载过程\n加载 根据全类名找到二进制数据，转换成方法区结构，生成一个Class对象作为方法区入口 验证 class文件格式检查 字节码语言检查 程序语义检查 类正确性检查 准备 分配内存 初始化零值 设置对象头 解析 常量池中符号引用转化成直接引用，获取类和字段在内存中的偏移量 初始化 执行clinit方法 使用 卸载 被GC回收/该类的所有实例对象被GC/该类的类加载器的实例被GC/该类没有被任何地方引用 类加载器 | 破坏双亲委派\nJVM参数 以及 线上排查问题思路\nGC日志记录\n-XX:+PrintGCDetails：打印基本 GC 信息 -XX:+PrintGCDateStamps：打印 GC 日期信息 -XX:+PrintTernuringDistribution：打印对象分布 -XX:+PrintHeapAtGC：打印堆数据 -XX:+PrintReferenceGC：打印Reference处理信息 -XX:+PrintGCApplicationStoppedTime：打印Stop The World的时间 -XX:+PrintSafepointStatistics：打印safepoint信息 -XX:PrintSafepointStatisticsCount=1：1个safepoint -Xloggc:/path/to/gc-%t.log：GC日志输出文件的文件路径 -XX:+UseGCLogFileRotation：开启日志文件分割 -XX:NumberOfGCLogFiles=14：最多分割几个文件，超过之后就从头开始写 -XX:GCLogFileSize=50M：每个文件大小上限 处理OOM\n-XX:+HeapDumpOnOutOfMemoryError ：遇到OOM时将heap转储到物理文件中 -XX:HeapDumpPath=./java_pid\u0026lt;pid\u0026gt;.hprof：写入文件的路径 -XX:OnOutOfMemoryError=\u0026quot;\u0026lt; cmd args \u0026gt;;\u0026lt; cmd args \u0026gt;\u0026quot;：当内存不足时会执行命令 -XX:+UseGCOverheadLimit：限制GC花费的VM时间比例 线上示例\n设置应用的元空间大小、堆内存大小、新生代大小、栈大小、Eden区和Survivor区比例\n1 ENV JAVA_OPTS=\u0026#34;-XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=128m -Xms512m -Xmx512m -Xmn128m -Xss256k -XX:SurvivorRatio=8\u0026#34; 以服务器模式启动、禁止系统调用System.gc()、使用ParNewGC为新生代垃圾回收器、CMS为老年代垃圾回收器、老年代使用的空间达到 70% 时就开始垃圾回收、 CMS 垃圾回收时卸载不再需要的类、并行处理软引用、弱引用和虚引用、在 CMS 的 remark 阶段之前进行一次 young generation 垃圾回收、出现内存溢出错误时导出堆信息、打印垃圾回收的详细信息，包括每次垃圾回收的详细情况、时间戳、堆的情况、应用暂停的时间等\n1 2 3 4 ENV JAVA_FIXED_ARGS=\u0026#34;-server -XX:+DisableExplicitGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly\\ -XX:CMSInitiatingOccupancyFraction=70 -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses -XX:+CMSClassUnloadingEnabled\\ -XX:+ParallelRefProcEnabled -XX:+CMSScavengeBeforeRemark -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCDetails\\ -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps\u0026#34; 设置JVM错误文件的路径地址(%p = pid)、发生OOM转储文件的路径、垃圾回收日志的路径(%t=timestamp)\n1 2 ENV JAVA_GC_LOG_PATH=\u0026#34;-XX:ErrorFile=/var/applog/gc/starfish-info-backend/hs_err_pid%p.log -XX:HeapDumpPath=/var/applog/gc/starfish-info-backend\\ -Xloggc:/var/applog/gc/starfish-info-backend/gc%t.log\u0026#34; 设置环境变量为生产环境\n1 ENV PARAMS=\u0026#34;--spring.profiles.active=prod\u0026#34; Dockerfile启动java进程的命令\n1 2 ENTRYPOINT [\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;java -Dloader.path=/app/libs/ -Djava.security.egd=file:/dev/./urandom -Dfile.encoding=UTF-8\\ $JAVA_OPTS $JAVA_FIXED_ARGS $JAVA_GC_LOG_PATH -jar /app/app.jar $PARAMS\u0026#34;] 堆结构:\n新生代 老年代 元空间 本地内存 Eden | S0 |S1 Ternured MetaSpace(初始20.8m) 代码缓存 + Thread (线程私有) -XX:NewSize=2048M -XX:MaxNewSize=3096M -Xmn2048m -XX:NewRatio=1 (老年代:新生代 = 1:1) -Xms8G -Xms8G -Xmx8G -Xmx8G -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m -Xss256k（栈大小） Spring Spring MVC SpringBoot Spring IOC \u0026amp; Spring AOP\nIOC: 将创建对象的控制权交给Spring容器 AOP: 在程序执行过程中动态织入代码,实现对横切关注点的模块化管理 Spring 核心流程图 （创建Bean过程）\n根据注解或配置文件获取Bean的定义 通过反射创建Bean的实例 通过set方法设置属性 如果实现了BeanNameAware|BeanClassLoaderAware|BeanFactoryAware接口，则调用对应的set方法 如果实现了BeanPostProcessor接口，则调用postProcessorBeforeInitialization()方法 如果实现了InitializingBean接口,则调用afterPropertiesSet方法 如果指定了init-method方法，则执行指定方法 如果实现了BeanPostProcessor接口，则调用postProcessorAfterInitialization()方法 使用Bean 如果实现了DisposableBean接口，则调用destory()方法 如果指定了destory-method方法，则执行指定方法 Spring AOP通知方式\n前置通知 后置通知 返回通知 异常通知 环绕通知 Spring 管理事务方式| 隔离级别 | 传播行为\n事务管理方式： 编程式： TransacationManager手动提交 声明式： xml|注解 (@Transactional) 自动提交 隔离级别： 采用数据库的隔离级别 (Default) 读未提交 (Read Uncommited) 读已提交 (Read Commited) 可重复读 (MySQL数据库的默认隔离级别 Repetable Read) 串行化 (Serializable) 传播行为： Requried：必须要有一个事务,没有就创建 Requried_New：必要需要有一个事务,有也创建 Support: 可以有一个事务,没有就以非事务运行 Not_Support: 有没有都以非事务运行 Mandatory: 必须要有一个事务,没有就抛异常 Never: 绝对不能有事务,有就抛异常 Nested: 有就嵌套事务,没有就创建 Spring MVC 流程\n客户端请求,DispatcherServlet拦截请求 DispatcherServlet调用HandlerMapping,HandlerMapping根据请求路径找到对应的Handler DispatcherServlet调用HandlerAdapter执行Handler Handler处理完请求后,返回ModelAndView给DispatcherServlet,Model是返回的数据对象,View是逻辑视图 DispatcherServlet调用ViewResolver对逻辑视图进行解析,找到真正的视图 DispatcherServlet把返回的Model传给视图进行渲染 把渲染后的视图返回响应 SpringBoot 常用注解 自动装配原理\n常用注解： @SpringBootApplication (@ComponetScan @Configuration @EnableAutoConfiguration = @Import( AutoConfigurationImportSelector))\n自动装配原理: SpringBoot通过@EnableAutoConfiguration注解实现了自动装配,@EnableAutoConfiguration通过AutoConfigurationImportSelector的getAutoConfigurationEntry方法,使用SpringFactoryLoader加载META-INF/Spring.factories文件,获取EnableAutoConfiguration指定的类,并过滤掉不满足Condition的类,实现自动装配.\n什么是SpringBootStarter 自定义Starter\nstarter是为SpringBoot提供一套快速的默认配置的机制，使用SpringFactoryLoader实现. 实现自定义starter需要: 1.导入Spring依赖 2.自定义配置类 3.编写META-INF/spring.factories，指定enableAutoConfiguration要加载的类 spring循环依赖怎么解决（说出三级缓存源码细节）\nSingletonObjects 一级缓存 存放成品Bean EarlySingletonObjects 二级缓存 存放过渡Bean包括原始Bean和代理Bean SingletonFactories 三级缓存 存放ObjectsFactory对象,实际使用getEarlyBeanReference()方法获取原始Bean或代理Bean 如果是只有两级缓存,代理Bean每次生成的对象会不一样,不满足Spring单例原则.\n2.6.X版本默认关闭循环依赖,如需开启在配置文件中指定spring.main.allow-circular-references=true\n前置条件:对象是单例的且开启了循环依赖,默认会将未初始化完成的Bean放入三级缓存中,循环依赖的对象会从三级缓存中找到依赖的对象,并在三级缓存销毁,放入二级缓存中.等初始化完成就从二级缓存中销毁,放入一级缓存中.\nMySQL MySQL基础架构 连接器 查询缓存 分析器 优化器 执行器 存储引擎 MySQL存储引擎 MyISAM | InooDB 区别如下 MyISAM不支持事务，InooDB支持事务 MyISAM和InooDBd都使用B+树作为数据结构，但实现方式不一样 MyISAM只有表锁，InooDB有行锁，表锁，读锁，写锁，MVCC等 MyISAM只有非聚簇索引，InooDB既有聚簇索引也有非聚簇索引 MyISAM不支持外键，InooDB支持外键 MyISAM不支持崩溃恢复，InooDB可以依赖redo log恢复数据 MySQL索引 聚簇索引 | 非聚簇索引 主键索引 | 普通索引,唯一索引,外键索引,联合索引,全文索引 最左前缀匹配原则： 使用联合索引时，有最左匹配原则，即从左往右，依次匹配 索引下推： 即将查询条件进行优化，直接过滤掉不满足条件的记录 为什么选择B+树作为索引的数据结构，有什么优点: IO查询稳定,范围查询更快. 一个高度为3的B+树最多能存多少条记录: ​\t记录数 = 根节点指针数 * 单个叶子节点记录数 ​ = 161024/(6(InnoDB指针大小)+4(int主键大小)/8(bigint主键大小)) * (16kb(页大小)/1kb(单条数据最大长度)) ​ = 161024/10(14) (一层容量指针数) * 16*1024/10(14) (二层容量指针数) * 16 ​ = 1170 * 1170 * 16 ​ = 21,902,400\n如果走辅助索引,最多需要经过几次IO: 3层 找到主键 再3层 找到数据 = 6次 MySQL日志 undo log 存放所有事务进行修改前的原始数据 用于保证事务的原子性,另外MVCC的实现依赖于:隐藏字段和Read View以及undo log. redo log 用于保证数据库的持久性,会先通过buffer pool去读或修改数据,然后记录到redo log上,等待刷盘. 存在刷盘机制,0-提交事务不刷盘,等待后台线程刷盘 1-提交事务就刷盘 2-提交事务写入文件缓存,等待后台线程刷盘 bin log 用于数据库备份,会记录所有涉及更新数据的逻辑操作. 为了解决写入redo log和bin log可能会出现不一致的情况，Mysql使用两阶段提交方案解决这个问题.\n在尚未提交事务时,会先prepare记录redo log. 在已提交事务时,会先写入bin log日志,然后在redo log日志进行commit,提交写入redo log. 即使在提交事务时,写入bin log发生异常,也不会有影响,只会回滚事务. 在写入redo log时发生异常,不会回滚事务,而是通过找到bin log来写入数据. MySQL事务\n特性: C是目的，AID是手段 A 原则性 C 一致性 I 隔离性 D 持久性 并发问题: 丢失修改: 修改操作被覆盖了 脏读: 读到了未提交的数据 不可重复读：两次读结果不一样 幻读： 两次读的结果变多了 解决方案： 锁 读锁（共享锁） 写锁（排他锁） 表锁 行锁 MVCC： 多版本并发控制，版本号唯一，使用隐藏字段、Read View、Undo log实现 事务隔离级别： 使用锁和MVCC共同实现 读未提交： 解决丢失修改 读已提交： 解决了丢失修改，脏读 可重复读： 解决了丢失修改，脏读，不可重复读 串行化： 解决了丢失修改，脏读，不可重复读，幻读 MySQL锁\n读锁（共享锁）： 锁兼容,读取时多个事务可同时获取. 一般不加锁，除非显式指定了 select \u0026hellip; lock in share mode / select \u0026hellip; for share\n写锁（排他锁）: 锁不兼容,修改时只能由一个事务获取. 一般不加锁，除非显式指定了 select \u0026hellip; for update\n表锁： 针对非索引字段加锁\n行锁： 针对索引字段加锁\n记录锁： Record Lock,单行记录上锁\n间隙锁： Gap Lock,多行记录上锁但不包括本身\n临键锁： Next-Key Lock = Record Lock + Gap Lock,多行记录上锁包括本身\nRR的事务隔离级别下，行锁默认使用临键锁，但操作主键索引或唯一键索引时，会降级成记录锁\n快照读： 即普通的select 语句，不加锁，读的是记录的历史版本.\n当前读： 即加了读写锁的select 语句，读的是记录的当前版本.\nMVCC实现 读： 读当前事务开始时间的版本数据 写： 创建一个新的版本，写入版本数据 在RR隔离级别下，如果是当前读（一致性锁定读）的情况下(for update/ insert / update / delete)，通过加入临键锁，锁住当前记录和范围，防止其他事务插入数据，出现幻读 但如果是快照读（一致性非锁定读），即使是RR隔离级别，也会出现幻读 实现方式： 隐藏字段 、 Read View 、 undo log\n隐藏字段\nDB_TRX_ID : 最后一次插入或更新该行的事务id DB_ROW_ID: 没有设置主键且没有唯一非空索引时，使用它来充当聚簇索引 DB_ROLL_PTR: 回滚指针,指向undo log Read View\n可见性判断,里面保存了\u0026quot;当前对本事务不可见的其他活跃性事务\u0026quot; m_low_limit_id: 目前出现过的最大的事务的ID+1,即下一个被分配事物的ID,大于等于这个ID的数据版本均不可见 m_up_limit_id: 活跃事务列表m_ids中最小的事务ID,如果m_ids为空,则等价于m_low_limit_id.小于这个ID的数据版本均可见 m_ids: Read View 创建时其他未提交的活跃事务的ID列表.创建Read View时,将当前未提交事务的ID记录下来,后续即使他们修改了记录行的值,对当前事务也是不可见的.m_ids不包括当前事务自己和已提交的事务. m_creator_trx_id: 创建该Read View的事务ID. undo log\n用于事务回滚，恢复到修改前的样子 用于MVCC，读历史版本的数据，实现一致性非锁定读 数据可见性算法 ： \u0026hellip;\n不可重复读问题:\nRC: 每次读都会有新的Read View记录,有不可重复读问题 RR: 事务开始时,只有第一次读有Read View记录,所以没有不可重复读问题 幻读问题:\nRR: 加入临键锁,解决幻读问题 MySQL执行计划分析\nexplain + SQL id： 查询序号 select_type： 查询类型，用于区分普通查询，联合查询，子查询等 SIMPLE： 简单查询，不含UNION或子查询 PRIMARY： 如果存在子查询，外层的SELECT标记为PRIMARY SUBQUERY： 子查询中的第一个SELECT UNION： 联合查询 DERIVED：在 FROM 中出现的子查询将被标记为 DERIVED UNION RESULT： UNION的查询结果 table：查询表名 partitions：匹配分区 type（重要）：表的访问方法 system：表中只有一行记录的情况下，访问方法是 system ，是 const 的一种特例 const：表中最多只有一行匹配的记录，一次查询就可以找到，常用于使用主键或唯一索引的所有字段作为查询条件 eq_ref： 当连表查询时，前一张表的行在当前这张表中只有一行与之对应。是除了 system 与 const 之外最好的 join 方式，常用于使用主键或唯一索引的所有字段作为连表条件 ref： 使用普通索引作为查询条件，查询结果可能找到多个符合条件的行 fulltext ref_or_null index_merge： 当查询条件使用了多个索引时，表示开启了 Index Merge 优化，此时执行计划中的 key 列列出了使用到的索引 unique_subquery index_subquery range：对索引列进行范围查询，执行计划中的 key 列表示哪个索引被使用了 index：查询遍历了整棵索引树，与 ALL 类似，只不过扫描的是索引，而索引一般在内存中，速度更快 ALL：全表扫描 possible_keys：查询可能用到的索引，null则可能没用到索引 key（重要）：实际用到的索引，null则没用到索引 key_len：索引最大长度，key=null那key_len=null ref：当使用索引等值查询时，与索引作比较的列或常量 rows：大致需要读取的行数，越小越好 filtered：条件过滤后的留存记录百分比 Extra（重要）：查询的额外信息 Using filesort: 排序时使用了外部索引进行排序，没用到内部索引进行排序 Using temporary： 创建临时表来存储查询结果，常见于order by 或 group by Using index: 使用了覆盖索引，不用回表，查询效率非常高 Using index condition： 查询优化器使用到了索引下推这个特性 Using where： 使用where条件进行了过滤，一般在没用到索引时出现 Using join buffer： 连表查询 MySQL优化\n避免隐式转换，隐式转换(两边数据类型不一致)会导致索引失效\n避免使用select * 而是使用 select 字段\n避免过多join表，不超过5个\n选择合适的字段类型\n避免出现大事务，拆分成小事务分批提交\n正确使用索引\n深度分页使用范围查询、子查询、延迟关联优化\n使用连续自增主键，而不是使用uuid(uuid范围查询无法排序)\nRedis Redis为什么快\n基于内存,访问快 基于Reactor模型开发了一套事件处理模型，主要是单线程事件循环和IO多路复用 内部使用了多种优化后的数据类型,效率高 常见的读写缓存策略\n旁路缓存模式（应用程序直接与「数据库、缓存」交互，并负责对缓存的维护） 读：先从缓存读，读不到由「应用程序」从数据库读取数据后返回，再把数据放入缓存 写：写入数据库，删掉缓存（服务端写） 读写穿透模式（应用程序与「缓存」交互，「缓存」与「数据库」交互,负责缓存的维护） 读：先从缓存读，读不到由「缓存」从数据库读，并将结果放入缓存,返回数据给应用 写：写入缓存，缓存不存在则更新数据库，存在则更新缓存,由「缓存」自己写数据库 异步缓存写入 (应用程序与「缓存」交互，「缓存」与「数据库」交互,负责缓存的维护) 读：先从缓存读，读不到从数据库读，再放入缓存后返回 写：写入缓存，不更新db,改为异步批量更新db Redis应用场景\n分布式锁 限流 消息队列 延时队列 分布式session Redis线程模型\n读写单线程，异步删除、网络请求多线程 基于Reactor模式开发了一套文件事件处理器，以单线程方式运行，以I/O多路复用来监听多个套接字 文件事件处理器 多个socket（客户端连接） I/O多路复用程序（支持多个连接） 文件事件分派器（将socket关联到事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） Redis数据结构以及应用场景\nString\n结构特点\nSDS(Simple Dynamic String)实现，好处在于\n可以扩容，避免缓冲区异常 获取字符串长度复杂度为O(1) 减少内存分配次数 二进制安全 使用场景\n存储token/session/userId，序列化后的对象等\n实现分布式锁(setnx key value) List\n结构特点 双向链表，支持反向查找和遍历 使用场景 最新文章、最新动态 Set\n结构特点 无序集合，类似Java中的HashSet 使用场景 网站UV统计，文章点赞/已读统计，关注 抽奖系统 Sorted Set(Zset)\n结构特点 类似TreeSet和HashMap的结合,但增加了个权重参数score,使得可以排序，还可以根据score范围查询 使用场景 排行榜 BitMap\n结构特点 key是元素本身，value是0/1，是一个存储0/1的数组，每个value占一个bit位 使用场景 用户签到情况、活跃用户情况、是否点赞/关注 HyperLogLog（基数统计）\n结构特点 基数计数概率算法，并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数） 使用场景 热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计 Geospatial\n结构特点 存储地理位置信息，基于 Sorted Set 实现 使用场景 附近的人 Redis持久化机制\n快照（snapshotting,RDB） 是Redis默认持久化方式，通过创建快照来获取数据在某个时间点的副本 默认使用bgsave进行持久化，通过创建子线程执行，而save操作会阻塞主线程 追加读（append-only file,AOF） 每条更改数据的命令会先放入缓冲区(server.aof_buf)，然后写入AOF文件，最后通过fsync策略来决定何时同步到硬盘. AOF工作流程 命令追加（append）: 写命令放入AOF缓冲区 文件写入（write）：将AOF缓冲区的数据写入系统内核缓冲区 文件同步（fsync）：AOF缓存区根据fsync策略向磁盘做同步操作，写入AOF文件 文件重写（rewrite）：AOF文件越来越来，需要定期重写来压缩AOF文件 重新加载（reload）: 通过加载AOF文件来恢复数据 fsync策略 appendfsync always: 主线程调用write执行完成后，后台线程（aof_fsync线程）立马调用fsync函数进行同步 (write + fsync) appenfsync eversec: 主线程调用write执行完成后，后台线程（aof_fsync线程）每秒调用fsync函数进行同步(write + 1秒 + fsync) appendfsync no：主线程调用write执行完成后，由操作系统决定什么时候调用fsync函数进行同步（write 不 fsync ,操作系统决定,Linux一般是30秒） rewrite 通过读取当前数据库的状态，然后生成一个新的AOF文件来替换旧的AOF文件 同时维护了一个AOF重写缓冲区,以记录创建过程中出现的写命令,等创建完成后,将写命令追加到新的AOF文件中 通过BGREWRITEAOF命令来触发重写操作,会创建一个子线程进行重写操作 混合（RDB+AOF） 使用aof-use-rdb-preamble命令开启混合持久化,AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头,但会导致可读性较差. 如何选择持久化 数据安全性要求高,选择RDB+AOF同时开启或者混合模式 数据安全性要求不高时,选择RDB 不建议只开启AOF,不易备份或快速重启恢复 Redis内存管理策略\n过期数据存储方式 通过字典(redisDb)来存储key的过期时间,由dict属性存储键值对,expires属性存储过期时间 过期数据删除策略 惰性删除 用到key时检查,是否需要删除.但会导致堆积过多过期key 定期删除 隔一段时间抽取一批key检查,是否需要删除. 内存淘汰机制 volatile-lru: 淘汰最近最少使用的数据 (已设置过期时间) volatile-ttl: 淘汰要过期的数据 (已设置过期时间) volatile-random: 随机淘汰数据 (已设置过期时间) allkeys-lru: 内存不足时,淘汰最近最少的数据 (全部) allkyes-random: 内存不足时,随机淘汰数据 (全部) no-eviction: 禁止写入数据 volatile-lfu: 淘汰最不经常使用的数据 (已设置过期时间) allkeys-lfu: 淘汰最不经常使用的数据 (全部) Redis生产问题\n缓存穿透 访问大量无效key,透过缓存,直接请求数据库 解决方案 缓存无效key 布隆过滤器 接口限流,IP黑名单 缓存击穿 缓存的热点数据过期或不存在,大量请求数据库 解决方案 缓存key时间设置比较长 提前预热热点数据 缓存雪崩 同一时间,大量缓存数据失效,大量请求数据库 解决方案 多级缓存 限流 缓存预热 缓存数据库一致性 旁路缓存模式: 先更新数据库,再删缓存. 增加缓存更新重试机制: 隔断时间重试删除缓存,或者引入消息队列来删缓存(删除缓存消息写入mq,mq来重试删除.) Redis集群\nRedis 多集群：主从模式,一主多从 （端口：6379） 优点: 简单 缺点: 需要手动维护主节点信息,发生故障需要手动恢复 Redis Sentinel：哨兵模式,一主多从,三哨兵 （端口：26379） 优点: 在主从模式的基础上,增加哨兵节点,以维护Redis节点状态,自动故障转移 缺点: 不好动态扩容 常见问题 有什么作用 监控：监控所有Redis节点状态 故障转移：如果master出现异常，Sentinel会实现故障转移，将一台slave升级成master 通知：通知新的master连接信息给slave，让它们执行replicaof成为新的master的slave 配置提供：通知新的master连接信息给客户端 检测节点是否下线 主观下线：某个Sentinel节点认为Redis节点下线（PING请求，PONG(LOADING/MASTERDOWN)超过响应时间） 客观下线：超过半数Sentinel节点认为Redis节点下线 如何选举新的master节点 slave在线: 节点必须在线 slave优先级：通过slave-priority设置优先级，最高的成为master,没有优先级就看复制进度 复制进度：数据最完整，复制进度最快的slave成为master runid: 如果优先级和复制进度一样，则runid最小的成为master Sentinel如何选举Leader 通过Raft算法选举出Leader Sentinel可以防止脑裂吗 发生网络隔离（也就是脑裂）时，master必须能写入slave，并能从节点得到响应。否则就拒绝接受新的写入命令 Redis Cluster：切片集群,三主三从（端口：6379和16379） 优点: 官方推荐,提供主从复制、故障转移功能,很⽅便地进⾏横向拓展,动态扩容和缩容是其最⼤的优势 缺点: 需要多服务器,适合数据量大,并发量⼤的场景 常见问题 如何分片 Redis使用哈希槽分区,每个键值对属于一个哈希槽.哈希槽 = key ^ CRC-16 % 16384 如何找到对应的哈希槽 根据Key通过上面的计算公式找到对应的哈希槽,然后再查询哈希槽和节点的映射关系 如果是当前节点负责就返回响应结果 如果不是则发送重定向错误,告诉客户端当前的哈希槽由哪个节点负责 客户端则向目标节点发送请求并更新缓存的哈希槽分配信息 为什么哈希槽是16384个(2^14) 哈希槽太大会导致心跳包变大,消耗带宽 哈希槽总数越少,对存储的哈希槽信息的bitmap压缩效果好 16384个槽节点占用空间2k(16384/8),空间小,并且不太会超过1000个主节点,完全够用 Redis Cluster 扩容缩容 扩容缩容的本质是重新分片,动态迁移哈希槽 提供重定向机制(ASK|MOVED),在发生扩容缩容时,仍能对外提供服务 Redis Cluster 节点通信 Cluster 各个节点使用Gossip协议通信,每个节点都维护了一份集群的状态信息 Cluster 内置了Sentinel机制,通过Gossip协议相互探测健康状态,发生故障自动切换 一致性哈希：\n分布式 分布式共识算法\nCAP理论 C|Consistency: 一致性, 所有节点访问同一份最新的数据副本 A|Availability: 可用性, 非故障节点在合理时间返回合理的响应 P|Partition Tolerance: 分区容错性,当出现网络分区时,仍能对外提供服务 一般时CP或AP架构,当发生网络分区时,P是一定需要保证的.选择CP还是AP就看业务场景 但没有发生网络分区时,CA是能同时保证的. CP架构: ZooKeeper | AP架构: Eureka | CP\u0026amp;AP架构: Nacos BASE理论 BA|Basically Available：基本可用, 允许损失部分可用性 S|Soft-state：软状态, 允许系统存在中间状态,且不会影响系统整体可用性 E|Eventually Consistent：最终一致性, 系统中的所有数据副本在经过一段时间同步后,最终会达到一致的状态. 当发生网络分区时，要保证AP时，会放弃C，而BASE理论则是不保证强一致性，但要保证最终一致性.是对AP方案的补充. Paxos算法 Basic Paxos：多节点就value达成共识 三种角色 提议者：接受客户端请求，发起提案（提案ID和提案value） 接受者：对提案进行投票，同时记住投票历史 学习者：超过半数投票的提案将会被执行运算，并发送给客户端 Multi Paxos：执行多个Basic Paxos Raft算法 拜占庭将军：在会出现故障或叛变节点时，需要保证系统的整体可用性 共识算法：即使面对故障，服务器也可以在共享状态上达成一致 基础 节点类型：某一时间，节点一定会是以下的身份类型 Leader：负责发起心跳，响应客户端，创建日志，同步日志 Candidate：发起竞选（Follower竞争Leader产生的临时角色） Follower：接受Leader的心跳和日志同步数据，投票给Candidate 任期：每次选举的开始就是一次任期（term），如果没有选出Leader将会开启下个任期和选举 日志： log = entry\u0026lt;term,index,cmd\u0026gt;[] ; 日志由entry数组构成，每一个事件成为一个entry，只有Leader可以创建entry； term = 任期；index = enry在log中下标；cmd = 应用到状态机的操作； 领导人选举： 使用心跳机制来触发选举，超过半数投票的Candidate获得选举，成为Leader Follower会自增term号并转换状态为Candidate，并向其他节点发起RequestVoteRPC请求，直到有Leader出现或进行下一轮选举 避免出现无限重复投票的情况，采用选举随机超时策略，增加一个选举随机超时时间 日志复制：Leader 和 Follower 的日志需要保持一致，不一致时会删除Follower不一致的地方，将Leader记录的后续日志发给Follower 安全性 选举限制 节点崩溃 时间与可用性 Gossip协议：分散式发散消息 集中式发散消息：一个节点向其他节点共享信息 分散式发散消息：每个节点周期性随机向其他节点共享信息 Redis Cluster 采用Gossip协议来进行共享信息，每个节点都维护了一份Redis集群的状态信息 消息传播模式 反熵：消除不同节点的数据差异，提高节点相似度，从而降低熵值（不确定性） 传谣（谣言传播）：一个节点一旦有了新数据就成为了活跃节点，活跃节点周期性向其他节点发送新数据，直到所有节点都有了新数据 差异： 反熵用于传播所有数据，传谣用于传播新数据 反熵一般需要设计一个闭环，传谣适合节点数量更多和动态变化的场景 API网关：请求转发 + 请求过滤\nNetflix Zuul\nZuul 主要通过过滤器（类似于 AOP）来过滤请求，从而实现网关必备的各种功能 Spring Cloud Gateway\nSpring Cloud Gateway 不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能,和 Zuul 2.x 的差别不大，也是通过过滤器来处理请求\n工作流程\n路由判断(Predicate)：先经过Gateway Handler Mapping处理，经过Predicate判断符合哪个路由规则，再映射到后端服务 请求过滤(Pre-Request)：然后请求到达Gateway Web Mapping处理，经过Filter Chain进行拦截和修改( 增加请求头、参数校验)，再转发请求到后端服务 服务处理(Handler)：后端处理请求 响应过滤(Post-Request)：后端处理请求完成后，返回给Gateway再次经过Filter Chain进行处理，再响应给客户端 响应返回：过滤处理完成后，响应给客户端 Predicate\n断言配置：满足断言的条件后，就能映射到指定的服务 动态路由：使用Nacos Server和Spring Cloud Alibaba Nacos Config实现动态路由，自动感知配置变化，动态配置网关信息\nFilter\nPre：请求到服务前，对请求进行拦截和修改，如参数校验，权限校验，流量监控，日志输出，协议转换等\nPost：请求处理完成后，对响应内容进行修改，如修改响应头、日志输出、流量监控\n限流：Sentinel 模块实现限流，提供两种资源维度的限流：route 维度和自定义 API 维度\n全局异常处理：实现ErrorWebExceptionHandler的Handle方法\nOpenResty\nOpenResty 是一个基于 Nginx 与 Lua 的高性能 Web 平台,通过简单的 Lua 语言来扩展网关的功能，比如实现自定义的路由规则、过滤器、缓存策略等 Kong\n基于OpenResty（Nginx + Lua），由Kong Server、Apache Cassandra/PostgreSQL、Kong Dashboard组成，本身就是一个 Lua 应用程序 APISIX\n基于 OpenResty 和 etcd Shenyu\n基于 WebFlux 分布式ID\n基本要求 全局唯一：ID 全局唯一性 高性能：生成速度要快 高可用：生成服务要可用 方便易用：拿来即用 解决方案 数据库主键自增（MySQL、Redis）：MySQL号段模式，Redis incr指令 UUID、Snowflake（雪花算法）：生成速度快，ID有序，比较灵活但有可能出现时钟回拨导致重复ID问题 UidGenerator：对雪花算法进行了改进，QPS更高，但18年后不再维护 Leaf：支持号段模式和雪花算法，支持双号段，解决了时钟回拨问题，QPS 压测结果近 5w/s Tinyid：基于数据库号段模式，支持双号段，纯本地操作，无 HTTP 请求消耗 IdGenerator：兼容所有雪花算法，解决了时钟回拨问题，不依赖外部存储系统，支持多语言调用 分布式锁\n基本要求\n互斥：任意一个时刻，锁只能被一个线程持有 高可用：当一个锁服务出现问题，能够自动切换到另外一个锁服务；即 锁一定会被释放 可重入：节点可重复获取锁 高性能：快速获取或释放锁 非阻塞：拿不到锁不能无限等待 解决方案\nMySQL实现\n通过唯一索引或排它锁实现，但有性能差、不具备锁失效等机制 Redis\nlua + setnx指令获取简易锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # KEYS[1]-lockKey, ARGV[1]--requestId, ARGV[2]--expire if redis.call(\u0026#39;setNx\u0026#39;, KEYS[1], ARGV[1]) == 1 then if tonumber(ARGV[2]) \u0026gt; 0 then redis.call(\u0026#39;expire\u0026#39;, KEYS[1], ARGV[2]) end return 1 else if redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1] then if tonumber(ARGV[2]) \u0026gt; 0 then redis.call(\u0026#39;expire\u0026#39;, KEYS[1], ARGV[2]) end return 1 else return 0 end end lua + del指令释放简易锁\n1 2 3 4 5 6 # 释放锁时，先比较锁对应的 value 值是否相等，避免锁的误释放 if redis.call(\u0026#34;get\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;,KEYS[1]) else return 0 end Redisson：锁的优雅续期\n使用Watch Dog来监控和续期锁，执行未完成，每隔10秒就执行续期操作，将超时时间设置为30秒 内置了可重入锁、自旋锁、公平锁、多重锁、红锁、读写锁 Zookeeper\n基于临时顺序节点和Watcher（事件监听器) 实现，推荐使用 Curator 来实现 ZooKeeper 分布式锁，是Netflix开源的ZooKeeper Java框架\n1 2 3 4 5 6 // 分布式可重入排它锁 InterProcessLock lock1 = new InterProcessMutex(client, lockPath1); // 分布式不可重入排它锁 InterProcessLock lock2 = new InterProcessSemaphoreMutex(client, lockPath2); // 将多个锁作为一个整体 InterProcessMultiLock lock = new InterProcessMultiLock(Arrays.asList(lock1, lock2)); 获取锁\n1 lock.acquire(10, TimeUnit.SECONDS) 释放锁\n1 lock.release() Etcd\n分布式事务\nCAP基础理论和BASE理论 一致性 强一致性：写什么读到的就是什么 弱一致性：不一定能读到最新值，只能在某个时刻能达到数据一致 最终一致性：保证一定时间内达到数据一致 柔性事务：追求最终一致，是BASE理论+业务实践，如TCC、Saga、MQ事务、本地消息表 TCC（补偿事务） Try 尝试阶段：尝试执行。完成业务检查，并预留好必须的业务资源 Confirm 确认阶段：确认执行。当所有参与者Try阶段执行成功时，就会执行Confirm，并处理预留的业务资源 Cancel 取消阶段：取消执行，释放Try预留的业务资源 常见框架：ByteTCC、Seata、Hmily Saga 长事务解决方案，将长事务拆分成多个本地短事务，每个短事务都会有个补偿动作，执行失败会恢复 MQ事务 RocketMQ：两阶段提交，超过最大重试次数，放入死信队列，手动处理，如果消息队列挂掉，数据库事务无法执行 QMQ：本地消息表，将分布式事务拆分成本地事务，即使消息队列挂掉也不影响数据库执行 刚性事务：追求强一致，如2PC、3PC 2PC（两阶段提交） 准备阶段：事务管理者向参与者询问本地事务操作是否执行成功，根据结果并不执行提交事务，而是进行提交阶段 提交阶段：事务管理者向参与者询问提交事务操作是否执行成功，根据结果来执行提交或回滚操作，完成后会结束当前分布式事务 存在问题 同步阻塞：事务阶段会一直占用相关资源，导致阻塞 数据不一致：网络问题导致部分参与者收不到comitt/rollback情况时，会导致数据不一致 单点问题：管理者挂掉会导致参与者一直卡在提交阶段 3PC（三阶段提交） 询问阶段：询问参与者能否执行本地数据库操作 准备阶段：当所有参与者都可执行时，才会执行本地事务操作，然后继续2PC阶段的步骤 提交阶段：同2PC阶段步骤 引入超时机制避免出现一直阻塞 分布式配置中心\nSpring Cloud Config Nacos Apollo RPC\n角色 客户端（服务消费端）：调用远程方法的一端 客户端Stub（桩）：代理类，将调用的类、方法、方法参数等传递到服务端 网络传输：将调用的信息传递到服务端，然后将服务器执行的结果返回给客户端 服务端Stub（桩）：服务端实际收到请求后，执行对应的方法并返回结果给客户端 服务端（服务提供端·）：提供远程方法的一端 原理 客户端（Client）以本地方式调用远程服务 客户端Stub收到调用后，将类、方法、方法参数组装成能进行网络传输的消息体（序列化）：RpcRequest 客户端Stub找到远程调用的地址，并将消息以序列化方式发送到服务提供端 服务端Stub收到消息将消息反序列化为Java对象：RpcRequest 服务端Stub根据RpcRequest的类、方法、方法参数调用本地方法 服务端Stub得到方法执行结果并将其组装成进行网络传输的消息体（序列化）：RpcResponse 客户端Stub接收到消息，并将其反序列化成为Java对象，得到最终结果 解决方案 Dubbo Motan gRPC Thrift Nacos | ElasticSearch | Kafka Nacos ElasticSearch Kafka 消息模型：发布-订阅模型 使用主题（Topic）作为消息通信载体，通过主题传递给所有订阅zhe 你还有什么要问我的吗 同级：能不能谈谈你作为⼀个公司⽼员⼯对公司的感受？ 领导： 部⻔的主要⼈员分配以及对应的主要⼯作能简单介绍⼀下吗？ 未来如果我要加⼊这个团队，你对我的期望是什么？ boss: 贵公司的发展⽬标和⽅向是什么? GC 日志\n2024-03-23T10:15:23.123-0800: 1.234: [GC (Allocation Failure) [PSYoungGen: 65536K-\u0026gt;16384K(76288K)] 65536K-\u0026gt;32768K(251392K), 0.0157545 secs] [Times: user=0.02 sys=0.01, real=0.02 secs] 2024-03-23T10:15:25.456-0800: 3.456: [GC (Allocation Failure) [PSYoungGen: 81920K-\u0026gt;20480K(76288K)] 98304K-\u0026gt;57344K(251392K), 0.0196028 secs] [Times: user=0.02 sys=0.01, real=0.02 secs] 2024-03-23T10:15:27.789-0800: 5.789: [Full GC (Ergonomics) [PSYoungGen: 20480K-\u0026gt;0K(76288K)] [ParOldGen: 36864K-\u0026gt;49152K(175104K)] 57344K-\u0026gt;49152K(251392K), [Metaspace: 20480K-\u0026gt;20480K(1067008K)], 0.1056299 secs] [Times: user=0.11 sys=0.01, real=0.11 secs] 2024-03-23T10:15:30.123-0800: 8.123: [GC (Allocation Failure) [PSYoungGen: 65536K-\u0026gt;16384K(76288K)] 114688K-\u0026gt;81920K(251392K), 0.0257884 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 2024-03-23T10:15:32.456-0800: 10.456: [GC (Allocation Failure) [PSYoungGen: 81920K-\u0026gt;20480K(76288K)] 139264K-\u0026gt;106496K(251392K), 0.0212413 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] 2024-03-23T10:15:34.789-0800: 12.789: [Full GC (Ergonomics) [PSYoungGen: 20480K-\u0026gt;0K(76288K)] [ParOldGen: 86016K-\u0026gt;90112K(200704K)] 106496K-\u0026gt;90112K(251392K), [Metaspace: 20480K-\u0026gt;20480K(1067008K)], 0.1468552 secs] [Times: user=0.14 sys=0.01, real=0.15 secs]\n","date":"2024-04-10T13:36:34+08:00","permalink":"https://blog.icharles.work/p/%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"面试知识点"},{"content":"人工智能 学习参考资料: 1.1.1 什么是神经网络 (captainbed.cn)\n神经网络 什么是神经网络 人工智能的神经网络受到人体大脑的启发，构建出来。\n在人的大脑中，有着数十亿叫神经元的细胞，它们连接成为一个网络。\n而在人工智能中，模仿人的大脑，也创建出N个神经元，它们连接成为神经网络。\n而每个神经元负责接受外部刺激，处理信息，转化成结果。\n数据传入神经网络 对于不同特征的数据（例如语音、图像、传感器或其他等等）在计算机中都会有对应的数字表示形式。通常它们会被转化成一个特征向量，传入到神经网络中。\n举例：假设一个图像有64*64个像素，每个像素就是一个颜色点，每个颜色点在(红(0-255),蓝(0-255),绿(0-255))三原色可以调配出所有色彩之间,\n所以在计算机中,3*64*64个颜色点构成这张图像 = 12288 总特征数,这个12288维特征向量就代表了这张图像.神经网络接收这个特征向量,预测并得出结果.\n神经网络如何进行预测 逻辑回归公式 预测的过程其实只是基于一个简单的公式(逻辑回归公式)：z = dot(w,x) + b x表示输入特征向量,如果有三个特征就可以用(x1,x2,x3)表示\nw表示权重,代表每个特征的重要程度\nb表示阈值,用于影响预测结果\ndot表示将w和x进行向量相乘\nz表示预测结果\n于是上面的公式展开后就成 z = (w1*x1 + w2*x2 + w3*x3) + b\n举例:\n假设你现在想喝奶茶,但现在天气不好,配送时间太长,而你又可能马上要下班了.\n那么影响结果的因素有3个特征,而你对每个因素的看重程度代表着权重,\n天气好不好对你不重要.\tw1=0,x1=1(w1=0表示无所谓,x1=1表示确实不好);\n配送时间太长有影响. w2=3,x2=1 (w2=3表示有一定程度影响但不大,x2=1表示确实有影响)\n马上要下班了,想马上回家. w3=6,x3=1(w3=1表示想回家的优先级很高,x3=0表示想回家)\n想回家的期望值很高. b=-10\n那么我们得出公式: z = (0*1 + 3*1 + 6*1) - 10 ,结果是-1.\n根据结果表示z\u0026lt;0则不会喝,z\u0026gt;0会喝,所以我们预测你不会现在想喝奶茶.\n激活函数 在实际的神经网络中,上面的逻辑回归只能适用于非常简单的逻辑.在复杂场景中计算得出的z值就不太准确,所以我们需要在逻辑回归外面再套一层函数.\n这个函数就叫做激活函数.下面简单介绍一种激活函数:sigmoid\n这个函数的作用是: 将z映射到[0,1]之间.x表示z值,y表示预测结果.可以看出,z越大,y越趋向于1,z越小,y越趋向于0.\n在刚才的例子中,假设z的结果是1,而y\u0026rsquo;值=0.8,则表示有80%的概率会买.但z值是-1,所以不会买.\n","date":"2024-01-04T13:41:04+08:00","permalink":"https://blog.icharles.work/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","title":"人工智能 - 神经网络"},{"content":"读创业有感 非常感谢Hawstein,以及他的文章一个独立创造者的五年,让我深受启发,在此记录观后心得.\n起点 - 梦想开始的地方 独立创造者的故事: Indie Hackers: Work Together to Build Profitable Online Businesses\n在这里每天会有独立创造者分享他们的故事,如果脑中缺少想要做什么东西的想法,不妨多看一看他人的故事.\n轴承 - 梦想的支撑 有了好的想法,甚至是有了自己的产品之后,需要处理的东西.\n银行账户 - 美国账户(BOA 支行) 海外支付服务提供商 - Stripe 电话 - SSN (Social Security Number)/EIN(Employer Identification Number) 注册公司 - Firstbase / Stripe Atlas 注意事项:\nStripe会要求提供美国政府签发的文件,以进一步验证账户所有人的名字以及地址,提供 办理 EIN 时 IRS 给的 147C 信件就可以了.\nEIN 则每个人都可以申请。更妙的是，你可以在 Fiverr 花点钱让别人帮你快速申请下来。\n使用Firstbase注册公司. Stripe Atlas 只能做 C 公司.\n使用Mercury用于银行业务.\n美国公司可以做到 0 交税（在美国只报税不交税）\n仔细选择免税地点，以避免双重征税 (https://incorporations.io/)\n挥棒 - 抓住梦想 产品可以停留在想法,待进行各方面的调研之后(竞品调研、用户调研、市场调研)，先沉淀下来。\n当想要实现的欲望越来越强烈时，就该主动出击，抓住机会。\n可以什么都不做。但是一旦发现一个绝佳好球，再全力挥棒.\n做MVP产品 , 快速发布 , 快速响应 , 快速调整.\n推广 - 梦想成为现实 朋友帮忙写好评 用户帮忙写好评 给潜在客户发私信或邮件 在互联网留下产品名字和官网链接 内容营销 付费广告(Google Ads) 推广佣金给用户 口碑传播 随想 在产品运行时,与客户沟通,搜集他们的问题和需求,也可能是成为一个新产品的机会. 在做产品时,碰到的问题或解决方案不够好时,也可能是成为一个新产品的机会. 与客户交朋友. 生意即艺术,享受做生意的过程,并在每一步都可以发挥自己的创造力.将会成为更好的产品. 遇见有趣的人或事,也是一种收获. ","date":"2024-01-04T13:36:34+08:00","permalink":"https://blog.icharles.work/p/%E8%AF%BB%E5%88%9B%E4%B8%9A%E6%9C%89%E6%84%9F/","title":"读创业有感"},{"content":"蜗牛壳攻略 刷蜗牛壳流程 准备物资: 火把 + 3个水壶 + 1个火腿棒 + 2-3个猪皮头盔 + 食物(找蓝蘑菇林,挖蘑菇+活木) 在石笋区找到蜗牛巢,将矿石放入背包,远离蜗牛巢一个屏幕距离放下背包,避免矿石吸引蜗牛仇恨攻击人物 用火把点燃蜗牛巢,概率刷新尖壳蜗牛和圆壳蜗牛,然后熄灭蜗牛巢.圆壳蜗牛会收到惊吓远离玩家,杀死会掉落蜗牛壳,尖壳蜗牛会回到蜗牛巢 用鼠标点击蜗牛攻击,避免F键打到蜗牛巢 注意事项: 点击右键缩壳,在缩壳状态下点击右键会脱下.可以使用走位或F键脱离缩壳状态. 缩壳5秒后可以脱离仇恨,但如果护甲被打掉,人物就会站起来,脱离仇恨失败. 清理远古流程 远古暴动 远古暴动分为四个周期,周期循环:\n平静期 : 影灯闭合,无影怪 危险指数: * 预警期 : 影灯开启,但无影怪 危险指数: ** 暴动期 : 影灯开启,并有大量影怪 危险指数: ***** 黎明期 : 影灯部分闭合,但有残留影怪 危险指数: *** 清理远古 远古分为几个区域,每个区域有不同数量的雕像和怪物\n五雕像区域 区域特征: 有5个雕像,1个主教和2个战车.\n清理思路: 站在主教外侧偏雕像的位置, F键攻击主教,并吸引战车撞主教. 当主教攻击或战车撞击时,缩壳躲避攻击. 利用战车清理雕像.\n八雕像区域 区域特征: 有8个雕像,2个主教.\n清理思路: 注意主教攻击时缩壳,就可以简单清理了.\n危险圣地 区域特征: 多个五雕像区域连接到了一起,同样每个区域会有1个主教和2个战车.但会有更多的发条怪.\n清理思路: 同五雕像区域,但注意别贪刀,多利用蜗牛壳躲避战车撞击.\n","date":"2023-08-30T12:11:12+08:00","permalink":"https://blog.icharles.work/p/%E9%A5%A5%E8%8D%92-%E8%9C%97%E7%89%9B%E7%A5%9E%E6%95%99/","title":"饥荒 蜗牛神教"},{"content":"初期建家 基础合成公式 工具 工具 材料1 材料2 材料3 火把 草*2 树枝*2 斧头 燧石*1 树枝*1 鹤嘴锄(铲子、剃刀) 燧石*2 树枝*2 锤子 石头*3 树枝*3 草*6 捕虫网 蜘蛛丝*2 树枝*4 绳子1(草3) 陷阱 草*6 树枝*2 黄金斧头(铲子、鹤嘴锄、干草叉、园艺锄) 金*2 树枝*4 长矛 燧石*1 树枝*2 绳子*1 背包 草*4 树枝*4 养蜂帽 蜘蛛丝*8 绳子*1 提灯 荧光果*2 树枝*3 绳子*2 火腿棒 猪皮*1 树枝*2 肉*2 橄榄球头盔 猪皮*1 绳子*1 牛角帽 牛角*1 牛毛*8 鼹鼠帽 电子元件*2 鼹鼠*2 发光浆果*1 排箫 曼德拉草*1 芦苇*5 绳子*1 建筑 建筑 材料1 材料2 材料3 精炼材料 木板=木*4 石砖=石头*3 绳子=草*3 电子元件 金子2+石砖1(石头*3) 莎草纸=芦苇*4 科技一本 金子*1 木*4 石头*4 科技二本 木板4(木16) 石砖2(石头6) 电子元件2(金4 石头*6) 魔法一本 兔子*4 木板4(木16) 高礼帽1(蜘蛛丝6) 魔法二本 活木*3 紫宝石*1 噩梦燃料*7 火坑 木*2 石头*12 烹饪锅 石砖3(石头9) 木炭*6 树枝*6 箱子 木板3(木12) 冰箱 金子*5 齿轮*1 石砖1(石头3) 晾肉架 木炭*2 树枝*3 绳子3(草9) 帐篷 蜘蛛丝*6 树枝*4 绳子*3 遮阳棚 蜘蛛丝*2 木板*4 绳子*3 猪屋 木板*4 石砖*3 猪皮*4 兔屋 木板*4 胡萝卜*10 兔绒*4 避雷针 金子*4 石头*3 捕鸟陷阱 树枝*3 蜘蛛丝*4 鸟笼 莎草纸*2 金子*6 种子*2 蜂箱 蜜蜂*4 木板*2 蜂巢*1 最小工具开局:\n燧石3+树枝10+草8+3石头(斧子 稿子 锤子 火把 铲子) 草4+树枝4(背包) 木头4+石头4+金子1(打包1本) 敲2个猪人房,金子4,大肉2,草6,树枝2(二本,火腿棒,头盔*2) 总共需要: 燧石3,石头7,树枝16,草18,金子5,大肉2\n以常规开局为例,需要准备的建筑有:\n日常: 1个石坑+1个帐篷+1个遮阳棚\n烹饪:2个冰箱+6个烹饪锅+6个晾肉架+1个鸟笼\n科技:1个科技2本(包含了科技1本) 1个魔法2本(包含了魔法1本)\n需要准备的材料有:\n木: 2+16+4+16+16 = 54 石头: 12+6+54+4+6+6 = 88 草: 9+9 = 18 金子: 10+12+1+4 = 27 木炭: 36 树枝: 4+36 = 40 蜘蛛丝: 6+2+6 = 14 齿轮:2 | 芦苇:8 | 种子:2 兔子:4 | 活木:3| 紫宝石:1|噩梦燃料:7 地图资源点 为了更快找到资源点,必须要做的事情: 跳每一个虫洞,下每一个洞穴\n龙蝇沙漠(必须找到) 绿洲沙漠(必须找到) 带海象的平原或森林(必须找到) 沼泽(必须找到) 猪王(必须找到) 蜂后(必须找到) 马赛克混合地区(可不找到) 带曼德拉草的森林(可不找到) ","date":"2023-07-29T12:11:12+08:00","permalink":"https://blog.icharles.work/p/%E9%A5%A5%E8%8D%92-%E5%88%9D%E6%9C%9F%E5%BB%BA%E5%AE%B6/","title":"饥荒 初期建家"},{"content":"ChatGPT使用技巧 基础篇 给定prompt更多,更精准的定义词或条件.\nWrite a short inspiring poem about OpenAI, focusing on the recent DALL-E product launch (DALL-E is a text to image ML model) in the style of a {famous poet}\n明确知道自己想要什么时,告诉它要做什么(to do),而不是不要做什么(not to do).\nPlease suggest me 10 essential words for IELTS\n不明确自己想要什么时,先告诉它不要什么(not to do)后,缩小范围,再告诉它要做什么(to do).\nPlease recommend me some places to visit in Hong Kong including amusement parks.\n在prompt中给出示例,基于示例回答.\n1 2 3 4 5 6 7 8 Suggest three names for an animal that is a superhero. Animal: Cat Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline Animal: Dog Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot Animal: Horse Names: 越完整的题目越容易生成更好的答案.\n1 2 3 4 5 6 7 8 9 如果一个房地产经纪人的佣金是某个房子的售价的6％，那么这个房子的售价是多少？ （1）售价减去房地产经纪人的佣金为84,600美元。 （2）购买价是36,000美元，售价是购买价的250%。 （A）仅陈述（1）足以回答问题，但仅陈述（2）不能回答问题。 （B）仅陈述（2）足以回答问题，但仅陈述（1）不能回答问题。 （C）两个陈述合起来足以回答问题，但没有一个陈述单独足以回答问题。 （D）每个陈述单独足以回答问题。 （E）陈述（1）和（2）合起来不能回答问题。 给出引导词,引导模型输出特定引导的内容.\n1 2 3 4 Create a MySQL query for all students in the Computer Science Department: Table departments, columns = [DepartmentId, DepartmentName] Table students, columns = [DepartmentId, StudentId, StudentName] SELECT 增加温度(temperature)，[0-2]的有效区间.\n如果你是梅西的追随者，请用100字表达情感。temperature=2\n加入角色，让内容更符合需求.\n假如你是一个 Redis 终端，我将输入命令，您将回复终端应显示的内容\n信息解释\nExplanation of what the code does:\n1 2 3 4 5 6 7 Python 3 def remove_common_prefix(x, prefix, ws_prefix): x[\u0026#34;completion\u0026#34;] = x[\u0026#34;completion\u0026#34;].str[len(prefix) :] if ws_prefix: \\# keep the single whitespace as prefix x[\u0026#34;completion\u0026#34;] = \u0026#34; \u0026#34; + x[\u0026#34;completion\u0026#34;] return x 用“”“(或###)将指令和文本分开,增加”“”会提升 AI 反馈的准确性.\ntext = f\u0026quot;\u0026quot;\u0026quot; You should express what you want a model to do by providing instructions that are as clear and specific as you can possibly make them. This will guide the model towards the desired output, and reduce the chances of receiving irrelevant or incorrect responses. Don\u0026rsquo;t confuse writing a clear prompt with writing a short prompt. In many cases, longer prompts provide more clarity and context for the model, which can lead to more detailed and relevant outputs. \u0026quot;\u0026quot;\u0026quot;\nprompt = f\u0026quot;\u0026quot;\u0026quot; Summarize the text delimited by triple backticks into a single sentence. {text} \u0026quot;\u0026quot;\u0026quot;\n指定内容进行提炼,按格式输出\nExtract the important entities mentioned in the article below. First extract all company names, then extract all people names, then extract specific topics which fit the content and finally extract general overarching themes Desired format: Company names: \u0026lt;comma_separated_list_of_company_names\u0026gt; People names: -||- Specific topics: -||- General themes: -||-\nText: \u0026ldquo;\u0026ldquo;\u0026ldquo;Powering Next Generation Applications with OpenAI Codex Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.\nMay 24, 2022 4 minute read OpenAI Codex, a natural language-to-code system based on GPT-3, helps turn simple English instructions into over a dozen popular coding languages. Codex was released last August through our API and is the principal building block of GitHub Copilot.\nWarp is a Rust-based terminal, reimagined from the ground up to help both individuals and teams be more productive in the command-line.\nTerminal commands are typically difficult to remember, find and construct. Users often have to leave the terminal and search the web for answers and even then the results might not give them the right command to execute. Warp uses Codex to allow users to run a natural language command to search directly from within the terminal and get a result they can immediately use.\n“Codex allows Warp to make the terminal more accessible and powerful. Developers search for entire commands using natural language rather than trying to remember them or assemble them piecemeal. Codex-powered command search has become one of our game changing features.”\n—Zach Lloyd, Founder, Warp\nMachinet helps professional Java developers write quality code by using Codex to generate intelligent unit test templates.\nMachinet was able to accelerate their development several-fold by switching from building their own machine learning systems to using Codex. The flexibility of Codex allows for the ability to easily add new features and capabilities saving their users time and helping them be more productive.\n“Codex is an amazing tool in our arsenal. Not only does it allow us to generate more meaningful code, but it has also helped us find a new design of product architecture and got us out of a local maximum.”\n—Vladislav Yanchenko, Founder, Machinet\u0026rdquo;\u0026rdquo;\u0026rdquo;\noutput:\nCompany names: OpenAI, Microsoft, GitHub, Pygma, Replit, Warp, Machinet People names: Emile Paffard-Wray, Amjad Masad, Zach Lloyd, Vladislav Yanchenko Specific topics: GPT-3, OpenAI API, Azure OpenAI Service, GitHub Copilot, Pygma, Replit, Warp, Machinet General themes: Natural language-to-code, Productivity, Problem solving, Creativity, Learning\n根据格式词,格式化输出\nSummarize the main points of the following speech Use the following format: Topic 1: \u0026lt;topic_name_1\u0026gt;\n\u0026lt;point_1\u0026gt; \u0026gt; .. \u0026gt; Topic 2: \u0026lt;topic_name_2\u0026gt; \u0026lt;point_1\u0026gt; \u0026gt; .. \u0026gt; Topic 10: .. Text: \u0026quot;\u0026quot;\u0026quot; Thank you so much, Fred, for that lovely introduction. And thanks to the Atlantic Council for hosting me today.\nThe course of the global economy over the past two years has been shaped by COVID-19 and our efforts to fight the pandemic. It’s now evident, though, that the war between Russia and Ukraine has redrawn the contours of the world economic outlook. Vladimir Putin’s unprovoked attack on Ukraine and its people is taking a devastating human toll, with lives tragically lost, families internally displaced or becoming refugees, and communities and cities destroyed. \u0026hellip;\n\u0026quot;\u0026quot;\u0026quot;\noutput\nTopic 1: The war in Ukraine\nThe war is taking a human toll with lives lost, families displaced, and communities destroyed The Biden administration is committed to holding Russia accountable The war has violated international law and is a challenge to the international order Topic 2: The global economy\nThe war is having negative impacts on the global economy, including higher commodity prices and inflation The IMF and World Bank will be focused on helping developing countries weather the impacts of the war The ultimate outcome for the global economy depends on the path of the war 高级篇 ChatGPT Prompt Framework Basic Prompt Framework Instruction（必须）： 指令，即你希望模型执行的具体任务。 Context（选填）： 背景信息，或者说是上下文信息，这可以引导模型做出更好的反应。 Input Data（选填）： 输入数据，告知模型需要处理的数据。 Output Indicator（选填）： 输出指示器，告知模型我们要输出的类型或格式 CRISPE Prompt Framework CR： Capacity and Role（能力与角色）。你希望 ChatGPT 扮演怎样的角色。 I： Insight（洞察力），背景信息和上下文（坦率说来我觉得用 Context 更好）。 S： Statement（指令），你希望 ChatGPT 做什么。 P： Personality（个性），你希望 ChatGPT 以什么风格或方式回答你。 E： Experiment（尝试），要求 ChatGPT 为你提供多个答案。 Chain of Thought Step of thought Let\u0026rsquo;s work this out in a step by step way to be sure we have the right answer.\nSelf-Consistency 推理路径A：\n商店有 10 个苹果。 店里有 8 个橙子。 卖了 6 个苹果。 卖了 4 个橙子。 还剩下 10 - 6 = 4 个苹果。 剩下 8 - 4 = 4 个橙子。 商店现在有 4 个苹果 + 4 个橙子 = 8 个水果。\n推理路径 B：\n商店最初有 10 个苹果和 8 个橙子。 商店卖了 6 个苹果，所以还剩下 10 - 6 = 4 个苹果。 商店卖了 4 个橙子，所以还剩下 8 - 4 = 4 个橙子。 商店现在有 4 个苹果 + 4 个橙子 = 8 个水果。\n","date":"2023-07-27T10:23:05+08:00","permalink":"https://blog.icharles.work/p/chatgpt%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"ChatGPT使用技巧"},{"content":"社交媒体三方平台 Twitter 接入前准备流程 申请Twitter账号,访问开发者平台并点击订阅 订阅选择套餐,此处为了演示我选择免费套餐.套餐如下图 填写描述信息,点击提交 参考示例:\n1 2 3 4 As a platform developer, my use cases of Twitter\u0026#39;s data and API include integrating real-time tweets into applications, allowing users to view and interact with trending topics, hashtags, and user profiles. Additionally, I leverage the API to enable users to post tweets, schedule tweets, and access their timelines. Analyzing user sentiment, engagement metrics, and trending content helps optimize content strategies. I also utilize Twitter\u0026#39;s data to gather insights for research and sentiment analysis. Ensuring compliance with Twitter\u0026#39;s data usage policies and user privacy is a priority in all use cases. 点击Keys and tokens,Regenerate重新生成API Key和API Key Secret,保存下来 点击User authentication settings模块下的Set up按钮,配置Twitter授权登录的必填信息 保存后会生成Client ID和Client Secret,保存下来 接入工作 导入Twitter API依赖 1 2 3 4 5 6 \u0026lt;!--twitter--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.twitter4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;twitter4j-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 参考Twitter API官方文档和twitter4j编写代码 创建授权凭据 1 2 3 4 5 6 7 8 9 ConfigurationBuilder cb = new ConfigurationBuilder(); cb.setDebugEnabled(true) .setOAuthConsumerKey(CONSUMER_KEY) .setOAuthConsumerSecret(CONSUMER_SECRET) .setOAuthAccessToken(ACCESS_TOKEN) .setOAuthAccessTokenSecret(ACCESS_TOKEN_SECRET); TwitterFactory tf = new TwitterFactory(cb.build()); Twitter twitter = tf.getInstance(); 访问API接口 1 2 3 4 5 6 7 8 9 10 11 12 /** * 获取用户时间线 */ User user = twitter.verifyCredentials(); System.out.println(\u0026#34;Welcome, @\u0026#34; + user.getScreenName() + \u0026#34;!\u0026#34;); Paging paging = new Paging(1, 10); // Get the first 10 tweets on the user\u0026#39;s timeline ResponseList\u0026lt;Status\u0026gt; timeline = twitter.getUserTimeline(paging); for (Status status : timeline) { System.out.println(status.getText()); } ","date":"2023-07-20T14:36:31+08:00","permalink":"https://blog.icharles.work/p/%E6%8E%A5%E5%85%A5%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93%E4%B8%89%E6%96%B9%E5%B9%B3%E5%8F%B0-twitter%E7%AF%87/","title":"接入社交媒体三方平台-Twitter篇"},{"content":"社交媒体三方平台 Youtube 接入前准备流程 申请Google账号,访问谷歌云平台 在导航栏中找到API和服务,进入已启用的API和服务,搜索YouTube Data API v3 进入YouTube Data API v3,点击启用 进入YouTube Data API v3API/服务详情,点击创建凭据 勾选用户数据,点击下一步,填写每一个步骤的信息,在第五步下载凭证,最后点击完成 注意,在范围中选择YouTube Data API v3的部分,按需选择\n下载凭证后,将凭证放入项目的config文件夹中,并重命名为client_secret.json 接入工作 导入YouTube API依赖 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!--Youtube--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.apis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;google-api-services-youtube\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;v3-rev20230123-2.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.api-client\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;google-api-client-gson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 参考YouTube API官方文档,编写代码 创建授权凭据(准备工作中的client_secret.json文件) 确定访问权限范围 运行授权请求 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 List\u0026lt;NameValuePair\u0026gt; parameters = new ArrayList\u0026lt;\u0026gt;(); parameters.add(new BasicNameValuePair(\u0026#34;code\u0026#34;, code)); parameters.add(new BasicNameValuePair(\u0026#34;client_id\u0026#34;, clientSecrets.getWeb().getClientId())); parameters.add(new BasicNameValuePair(\u0026#34;client_secret\u0026#34;, clientSecrets.getWeb().getClientSecret())); parameters.add(new BasicNameValuePair(\u0026#34;grant_type\u0026#34;, \u0026#34;authorization_code\u0026#34;)); parameters.add(new BasicNameValuePair(\u0026#34;redirect_uri\u0026#34;,redirectUri)); UrlEncodedFormEntity encodedFormEntity = new UrlEncodedFormEntity(parameters, StandardCharsets.UTF_8.name()); String url = \u0026#34;https://oauth2.googleapis.com/token\u0026#34;; HttpPost request = new HttpPost(); request.setEntity(encodedFormEntity); String response = HttpClientUtil.doPost(url, encodedFormEntity); System.out.println(response); TokenResponse tokenResponse = JSON.parseObject(response,TokenResponse.class); Credential credential = flow.createAndStoreCredential(tokenResponse, state); CREDENTIAL_MAP.put(state,credential); 访问API接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * 上传视频接口 * @return */ Credential credential = YoutubeAuthController.CREDENTIAL_MAP.get(uid); YouTube youtubeService = new YouTube.Builder(httpTransport, jsonFactory, credential).build(); Video uploadedVideo = new Video(); VideoStatus status = new VideoStatus(); status.setPrivacyStatus(\u0026#34;public\u0026#34;); uploadedVideo.setStatus(status); VideoSnippet snippet = new VideoSnippet(); snippet.setTitle(file.getOriginalFilename()); uploadedVideo.setSnippet(snippet); InputStreamContent mediaContent =new InputStreamContent(\u0026#34;application/octet-stream\u0026#34;,new BufferedInputStream(file.getInputStream())); YouTube.Videos.Insert videoInsert = youtubeService.videos().insert(\u0026#34;snippet,status,id,player\u0026#34;, uploadedVideo, mediaContent); MediaHttpUploader uploader = videoInsert.getMediaHttpUploader(); uploader.setDirectUploadEnabled(false); MediaHttpUploaderProgressListener progressListener = e -\u0026gt; { switch (e.getUploadState()) { case INITIATION_STARTED: System.out.println(\u0026#34;Initiation Started\u0026#34;); break; case INITIATION_COMPLETE: System.out.println(\u0026#34;Initiation Completed\u0026#34;); break; case MEDIA_IN_PROGRESS: System.out.println(\u0026#34;Upload in progress\u0026#34;); System.out.println(\u0026#34;Upload percentage: \u0026#34; + e.getProgress()); break; case MEDIA_COMPLETE: System.out.println(\u0026#34;Upload Completed!\u0026#34;); break; case NOT_STARTED: System.out.println(\u0026#34;Upload Not Started!\u0026#34;); break; } }; uploader.setProgressListener(progressListener); videoInsert.execute(); ","date":"2023-07-19T10:06:18+08:00","permalink":"https://blog.icharles.work/p/%E6%8E%A5%E5%85%A5%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93%E4%B8%89%E6%96%B9%E5%B9%B3%E5%8F%B0-youtube%E7%AF%87/","title":"接入社交媒体三方平台-Youtube篇"},{"content":" 很多人在你刚开始时就给你提供建议,告知风险以及需要承担的后果,但我想告诉你的是:想到就去做,不然点子就只会点子而不是现实.\n想到就去做(Just do it!) 一个点子(新的或者是借鉴别人的) 一份计划书 启动金 ","date":"2023-07-18T16:56:44+08:00","permalink":"https://blog.icharles.work/p/%E5%AD%A6%E4%B9%A0cy_starup%E8%AF%BE%E7%A8%8B%E6%9C%89%E6%84%9F/","title":"学习CY_StarUp课程有感"},{"content":"Shortcodes Stack 附带了一组可以在内容中使用的短代码。 此页面仅包含特定于 Stack 的短代码。Hugo 的内置短代码记录在此处。\n下面为了避免代码执行,在\u0026lt;\u0026gt;侧加了转义符\u0026rsquo;',使用时去掉\n哔哩哔哩视频 1 {{\\\u0026lt; bilibili VIDEO_ID PART_NUMBER \\\u0026gt;}} 腾讯视频 1 {{\\\u0026lt; tencent VIDEO_ID \\\u0026gt;}} Youtube 视频 1 {{\\\u0026lt; youtube VIDEO_ID \\\u0026gt;}} 通用视频文件 1 2 {{\\\u0026lt; video VIDEO_URL \\\u0026gt;}} {{\\\u0026lt; video src=\u0026#34;VIDEO_URL\u0026#34; autoplay=\u0026#34;true\u0026#34; poster=\u0026#34;./video-poster.png\u0026#34; \\\u0026gt;}} 可以VIDEO_URL是 URL 或相对于目录的路径static。 例如，src=\u0026quot;/video/my-video.mp4\u0026quot;将嵌入您网站文件夹的视频文件static/video/my-video.mp4。 该autoplay属性是可选的。它可用于指定是否应自动播放视频。该poster属性是可选的。它可用于指定视频的海报图像。\nGitLab 1 {{\\\u0026lt; gitlab SNIPPET_ID \\\u0026gt;}} 可以SNIPPET_ID在片段的 URL 中找到。例如，https://gitlab.com/-/snippets/1234567 为1234567。\n引用 1 2 3 {{\\\u0026lt; quote author=\u0026#34;A famous person\u0026#34; source=\u0026#34;The book they wrote\u0026#34; url=\u0026#34;https://en.wikipedia.org/wiki/Book\u0026#34; \\\u0026gt;}} Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. {{\\\u0026lt; /quote \\\u0026gt;}} ","date":"2023-07-18T12:11:12+08:00","permalink":"https://blog.icharles.work/p/stack%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/","title":"Stack使用方式"},{"content":"奶奶岛篇 任务 完成下面任务会增加好感度,但重复完成任务不会增加好感度, 参考视频: https://www.bilibili.com/video/BV1nk4y1N7Uv/?p=17\u0026spm_id_from=pageDriver\n任务一:修房子 一阶段:收集10个木板,10个饼干切割机壳(盐水浅滩群系,带新鲜火腿棒+船补丁),1只萤火虫(捕虫网捕捉) 二阶段:收集10个大理石,5个石砖,3个荧光果 三阶段:收集10个月岩,5个绳子,5个地毯地板 任务二:种植 蜂巢周围种十朵花 种植8个浆果丛并施肥 任务三:杀花 春季,蜂箱旁会刷食人花,杀死食人花 任务四:清理垃圾 用夹夹绞盘打捞岛旁的水中垃圾 任务五:送伞 下雨时给奶奶送伞(花伞,雨伞,眼球伞,暗影伞均可) 任务六:保暖 下雪时给奶奶送保暖衣物(透气背心,松软背心,犬牙背心,熊皮背心均可) 任务七:晒肉 岛上的6个晒肉架,晒肉 任务八:喂食 给奶奶吃花沙拉(需要仙人掌花材料) ","date":"2023-07-18T12:11:12+08:00","permalink":"https://blog.icharles.work/p/%E9%A5%A5%E8%8D%92-%E5%A5%B6%E5%A5%B6%E5%B2%9B%E7%AF%87/","title":"饥荒 奶奶岛篇"}]